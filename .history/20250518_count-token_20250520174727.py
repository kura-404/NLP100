import csv
import tiktoken
from datetime import datetime
import os
import pandas as pd

# === è¨­å®š ===
file_path = '/Users/kuramotomana/Test/å…¨èª²é¡Œãƒ‡ãƒ¼ã‚¿æŠ½å‡º.csv'  # .csv ã¾ãŸã¯ .xlsx ã«å¯¾å¿œ
target_column_name = "ç ”ç©¶æ¦‚è¦"
max_tokens_per_list = 8000

# === ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆæº–å‚™ï¼ˆGPT-4o-miniç›¸å½“ï¼‰ ===
encoding = tiktoken.get_encoding("cl100k_base")
def count_tokens(text: str) -> int:
    return len(encoding.encode(text))

# === ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã§åˆ†å²ã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã‚’æŠ½å‡º ===
unique_values = set()
ext = os.path.splitext(file_path)[1].lower()

if ext == ".csv":
    with open(file_path, newline='', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            if target_column_name in row:
                value = row[target_column_name].strip()
                if value:
                    unique_values.add(value)
elif ext in [".xlsx", ".xls"]:
    df = pd.read_excel(file_path)
    if target_column_name in df.columns:
        for value in df[target_column_name].dropna().unique():
            value = str(value).strip()
            if value:
                unique_values.add(value)
else:
    raise ValueError("å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚CSVã‹Excelã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

# === ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§ãƒªã‚¹ãƒˆåˆ†å‰² ===
lists = []
current_list = []
current_tokens = 0

for value in sorted(unique_values):
    tokens = count_tokens(value)
    if current_tokens + tokens > max_tokens_per_list:
        lists.append(current_list)
        current_list = [value]
        current_tokens = tokens
    else:
        current_list.append(value)
        current_tokens += tokens
if current_list:
    lists.append(current_list)

# === å‡ºåŠ›æº–å‚™ ===
output_lines = []
output_lines.append(f"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®æ•°: {len(unique_values)}")
output_lines.append(f"âœ… å…¨ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: {sum(count_tokens(v) for v in unique_values)}")
output_lines.append(f"âœ… ãƒˆãƒ¼ã‚¯ãƒ³{max_tokens_per_list}ä»¥å†…ã«åã¾ã‚‹ãƒªã‚¹ãƒˆæ•°: {len(lists)}\n")

for i, lst in enumerate(lists):
    token_count = sum(count_tokens(v) for v in lst)
    output_lines.append(f"  â–¶ List {i+1}: {len(lst)}é …ç›®, åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•° = {token_count}")

output_lines.append(f"\nğŸ§¾ å…¨ä½“ã®ãƒªã‚¹ãƒˆæ•°ï¼ˆåˆ†å‰²ã•ã‚ŒãŸãƒªã‚¹ãƒˆã®å€‹æ•°ï¼‰: {len(lists)}")

# === ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆï¼ˆç¾åœ¨æ™‚åˆ»ï¼‹å…ƒãƒ•ã‚¡ã‚¤ãƒ«åï¼‰===
base_name = os.path.splitext(os.path.basename(file_path))[0]
timestamp = datetime.now().strftime("%Y%m%d_%H%M")
output_filename = f"/Users/kuramotomana/Test/{timestamp}_{base_name}_token_report.txt"

# === ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ ===
with open(output_filename, "w", encoding="utf-8") as f:
    f.write("\n".join(output_lines))

print(f"ğŸ“ çµæœã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {output_filename}")

with open(output_filename, "w", encoding="utf-8") as f:
    f.write("\n".join(output_lines))

print(f"ğŸ“ çµæœã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {output_filename}")