#æˆæœæ¦‚è¦ï¼ˆæ–°ç”Ÿç‰©ï¼‰ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«125000ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã‚’å‚è€ƒã«ã—ã¦1ä»¶ã®æ¶ç©ºã®æˆæœæ¦‚è¦ã‚’ç”Ÿæˆã™ã‚‹ã€‚åŠ ãˆã¦ã€å‚è€ƒã«ã—ãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸€ç•ªä¼¼ã¦ã„ã‚‹ã‚‚ã®ã¨ã®é¡ä¼¼åº¦ã€å·®åˆ†ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
import pandas as pd
import tiktoken
import json
import random
import time
import difflib
from openai import OpenAI
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI()

# ãƒˆãƒ¼ã‚¯ãƒ³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€
encoding = tiktoken.get_encoding("cl100k_base")
def count_tokens(text: str) -> int:
    return len(encoding.encode(text))

# åŸ‹ã‚è¾¼ã¿å–å¾—
def get_embedding(text: str) -> list:
    response = client.embeddings.create(
        input=[text],
        model="text-embedding-3-small"
    )
    return response.data[0].embedding

# è¨­å®š
MAX_INPUT_TOKENS = 125000
MAX_OUTPUT_TOKENS = 2000
FILE_PATH = "/Users/kuramotomana/Test/20250602_æœ€æ–°å¹´åº¦.xlsx"

# çœç•¥éƒ¨åˆ†ï¼šOpenAIã‚„ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚«ã‚¦ãƒ³ãƒˆã®åˆæœŸè¨­å®šãªã©ã¯ã“ã‚Œã¾ã§ã¨åŒã˜

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
df = pd.read_excel(FILE_PATH)
df_filtered = df[df["å¯¾è±¡ç–¾æ‚£"].astype(str).str.contains("æ–°ç”Ÿç‰©", na=False)]
df_filtered = df_filtered.dropna(subset=["æˆæœæ¦‚è¦ï¼ˆæ—¥æœ¬èªï¼‰"])
examples_pool = df_filtered[["èª²é¡Œç®¡ç†ç•ªå·", "æˆæœæ¦‚è¦ï¼ˆæ—¥æœ¬èªï¼‰"]].values.tolist()

# ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã¨è©°ã‚è¾¼ã¿
random.shuffle(examples_pool)
example_text = ""
total_tokens = 0
examples_used = []

for ex_id, ex_text in examples_pool:
    line = f"- {ex_text.strip()}\n"
    tokens = count_tokens(line)
    if total_tokens + tokens > MAX_INPUT_TOKENS:
        break
    example_text += line
    total_tokens += tokens
    examples_used.append((ex_id, ex_text.strip()))

# ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨APIå‘¼ã³å‡ºã—ã¯åŒæ§˜

# é¡ä¼¼åº¦è¨ˆç®—
emb_generated = get_embedding(generated)
emb_examples = [get_embedding(text) for _, text in examples_used]
similarities = cosine_similarity([emb_generated], emb_examples)[0]
most_similar_index = int(np.argmax(similarities))
most_similar_id, most_similar_text = examples_used[most_similar_index]
similarity_score = similarities[most_similar_index]

# å·®åˆ†ã¨ä¿å­˜
with open(f"{base_filename}_æ¯”è¼ƒçµæœ.txt", "w", encoding="utf-8") as f:
    f.write("ğŸ§ª ç”Ÿæˆã•ã‚ŒãŸæˆæœæ¦‚è¦\n")
    f.write(generated + "\n\n")
    f.write("ğŸ” æœ€ã‚‚é¡ä¼¼ã—ãŸå‚è€ƒæˆæœæ¦‚è¦\n")
    f.write(f"èª²é¡Œç®¡ç†ç•ªå·: {most_similar_id}\n")
    f.write(most_similar_text + "\n\n")
    f.write(f"ğŸ”— é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {similarity_score:.4f}\n\n")
    f.write("ğŸ§¬ å·®åˆ†ï¼ˆå˜èªå˜ä½ï¼‰\n")
    f.write("\n".join(difflib.ndiff(generated.split(), most_similar_text.split())))