# 成果概要書き換えプロジェクト（TEST）

このプロジェクトでは、大規模言語モデル（LLM）を用いた成果概要の書き換えと、その結果の自動評価を目的としています。  
BLEU、ROUGE-L、BERTScore などの評価指標を使い、各手法の出力を比較・分析します。

---

## 📁 ディレクトリ構成

```
TEST/
├── Input/                            # 入力データ
│   └── 7件.csv                       # 書き換えデータ＋一部アノテーション付き
│
├── Output/                           # 評価結果・書き換え結果
│   ├── 20250715_204151_BERTScore.csv
│   ├── 20250715_204946_BLEUScore.csv
│   ├── 20250715_205259_ROUGEScore.csv
│   └── rewritten_output_20250715_200051.csv
│
├── PyFile/
│   ├── Cal/                          # 評価スクリプト（指標計算）
│   │   ├── bertScore.py              # BERTScore を計算（要引数）
│   │   ├── bleu.py                   # BLEU スコアを計算（要引数）
│   │   └── rouge.py                  # ROUGE-L を計算（要引数）
│   │
│   ├── Rewrite/                      # 書き換えスクリプト
│   │   ├── 20250708_usechecklist-before.py   # オリジナルにチェックリスト適用
│   │   ├── 20250709_usechecklist-after.py    # 書き換え後にチェックリスト適用
│   │   └── change-result.py                  # 改良プロンプトによる書き換え
│   │
│   └── TestCal/                      # 評価スクリプトのテスト用コード
│       ├── bert_test.py
│       ├── bleu_test.py
│       └── rouge_test.py
│
└── README.md                         # このファイル
```

---

## 📝 Input/7件.csv の内容

- 書き換え対象の成果概要と、複数の書き換えパターンが記載されたCSV
- 一部行には人手によるアノテーションあり

🔸 カラム構成（例）※必要に応じて修正：
| カラム名 | 内容 |
|----------|------|
| original_text | 元の成果概要 |
| rewritten_LLM_BM | LLMによるベースライン書き換え |
| rewritten_prompt_improved | 改良プロンプトによる書き換え |
| rewritten_checklist_before | チェックリスト前適用版 |
| rewritten_checklist_after | チェックリスト後適用版 |
| annotation_quality | 🔸（手動付与された評価指標など、内容を明記してください） |

---

## 🛠 書き換えスクリプトの説明（PyFile/Rewrite）

- `20250708_usechecklist-before.py`  
  → オリジナルテキストにチェックリストを使って書き換えを行う

- `20250709_usechecklist-after.py`  
  → すでに書き換え済みのテキストにチェックリストを適用

- `change-result.py`  
  → 改良プロンプトを使用し、オリジナル文を再生成するスクリプト

🔸 使用方法や引数がある場合は、それぞれのスクリプト内に記述してください

---

## 📈 評価スクリプトの説明（PyFile/Cal）

各スクリプトは、入力CSVを受け取り、出力CSVに評価スコアを書き込みます。

- 使用例（共通形式）：

```bash
python <スクリプト名>.py <入力CSVパス> <出力CSVパス>
```

- 各スクリプトの概要：

| スクリプト | 概要 |
|------------|------|
| `bertScore.py` | BERTScore を計算してCSV出力 |
| `bleu.py`      | BLEU スコアを計算してCSV出力 |
| `rouge.py`     | ROUGE-L を計算してCSV出力 |

🔸 引数の順番・形式・必要条件などは、各スクリプト内の docstring に記述しておくことを推奨します。

---

## 📤 出力ファイルの説明（Output/）

| ファイル名 | 内容 |
|------------|------|
| `*_BERTScore.csv` | 各書き換え手法に対する BERTScore の結果 |
| `*_BLEUScore.csv` | 各書き換え手法に対する BLEU スコアの結果 |
| `*_ROUGEScore.csv` | 各書き換え手法に対する ROUGE-L の結果 |
| `rewritten_output_*.csv` | 改良プロンプトで生成された新しい成果概要 |

🔸 各スコアファイルのカラム構成：
- `ID`
- `BLEUScore_生成された成果概要`
- `BLEUScore_LLMによる書き換え（BM）`
- `BLEUScore_改良プロンプトによる書き換え`
- `BLEUScore_Beforeチェックリスト`
- `BLEUScore_初期プロンプト適用`
- `BLEUScore_Afterチェックリスト`
など（ROUGE や BERTScore も同様の形式）

---

## 📦 使用ライブラリ（想定）

以下は主に使われている可能性のあるライブラリです。`requirements.txt` の作成を推奨します。

```text
transformers
nltk
rouge-score
bert_score
pandas
```

---

## 🔄 実行手順（ワークフロー）

基本的にはスクリプト単体で実行可能です。

1. 書き換えスクリプトを必要に応じて実行し、新しいテキストを生成
2. Cal スクリプトで評価指標を計算し、結果を Output に保存

📌 Calスクリプトは必ずコマンドライン引数として `入力ファイルパス` と `出力ファイルパス` を指定してください。

---

## 📚 補足情報

- 個人プロジェクト（研究発表のための作業ログ）
- 一部データは公開する可能性あり
- 現時点では非公開／ローカル利用目的で運用中

---