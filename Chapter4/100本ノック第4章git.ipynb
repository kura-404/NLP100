{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGFQlLu5789s"
   },
   "source": [
    "# セットアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuM2B0xR7ynY"
   },
   "source": [
    "[リンクテキスト](https://qiita.com/kinakomochi_/items/95990d139f5e5e57fd67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134175,
     "status": "ok",
     "timestamp": 1753409932376,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "xZ3YFCS53hfn",
    "outputId": "eaf26334-9248-4884-b864-d1a357f9a681"
   },
   "outputs": [],
   "source": [
    "!pip install -U ginza ja_ginza_electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10979,
     "status": "ok",
     "timestamp": 1753409943366,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "oZSRTApy4F_V",
    "outputId": "87e74bda-9523-4030-a238-3f1bccc8e74d"
   },
   "outputs": [],
   "source": [
    "!pip install -U ginza ja-ginza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1753409943562,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "THylGzOr4sya",
    "outputId": "a0d727d7-b4c7-483c-94aa-da76fd3611a3"
   },
   "outputs": [],
   "source": [
    "import pkg_resources, imp\n",
    "imp.reload(pkg_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526,
     "referenced_widgets": [
      "fe36056dbabd4d809e668dc7428d8376",
      "fe5be0e201164fe98aaa81c8b08a32d9",
      "b5da8544ce0c4eb09bd160333d5d12c6",
      "24005e0fe9f04f9aa573ce53c86eb5a4",
      "dafe8ca14a71423a8c06a440cdeae523",
      "b0630d9b10224b43bb2eceadb7992bdb",
      "6f8c4537891c47649d296c534cf91143",
      "db5194291b4d4afe9fc9392c4ca11f45",
      "1f8058a0b38143aea0cf69d530182a50",
      "04c07baa3d9e43a09c966c3e3e4d829c",
      "a3f0e54ddcf7402ea2422492a9ccb789",
      "5c6aeec454ff4c2ebfc4b8b517ff2286",
      "df08875f452f4f8eb782a77b81181ab7",
      "ec01132384d3451bbe1f11d7d01ea1fc",
      "e5f4ef90ba6d4878bde4aa82fea00a80",
      "1f9abaef471d4368b29c0563c73cfb95",
      "e6147dbcf8a140d2b4c83f46a68b6e93",
      "2c93f4293ada48bdb0f3d9ceffe6420e",
      "8e59a2b3a1334067b7c01de8468b0db8",
      "0ebf3333a21b421b9353634070b81147",
      "81d3be9c484c420f91a2ac0377fe365b",
      "4c09d495a6454bc5aabcc462855fa582"
     ]
    },
    "executionInfo": {
     "elapsed": 35401,
     "status": "ok",
     "timestamp": 1753409978975,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "KbWm2god4wUt",
    "outputId": "e544d152-5964-4d98-b69a-81b95c00e9e2"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza_electra')  # または 'ja_ginza'（インストール済みモデル名に応じて）\n",
    "doc = nlp('文書の形態素解析をしてみたよ')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        print(\n",
    "            token.i,                        # トークンのインデックス\n",
    "            token.orth_,                    # 表層形\n",
    "            token.lemma_,                   # 基本形\n",
    "            token.norm_,                    # 正規化形\n",
    "            token.morph.get(\"Reading\"),     # 読み\n",
    "            token.pos_,                     # 品詞\n",
    "            token.morph.get(\"Inflection\"),  # 活用形\n",
    "            token.tag_,                     # 詳細品詞タグ\n",
    "            token.dep_,                     # 係り受け関係\n",
    "            token.head.i                    # 係り先のトークンインデックス\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LgAVC6uAQ80"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5766,
     "status": "ok",
     "timestamp": 1753409984804,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "O4o7eTNzNfPi",
    "outputId": "860df74e-55c3-4ef0-fec0-d8f9155f72ac"
   },
   "outputs": [],
   "source": [
    "!pip install nbstripout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1753409985277,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "3iYjLUA1NjKC",
    "outputId": "e709ea67-0ebf-41e9-9fbd-febf373aecba"
   },
   "outputs": [],
   "source": [
    "!nbstripout 100本ノック第4章.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVNGL-b88Csx"
   },
   "source": [
    "# 33\n",
    "文章textに係り受け解析を適用し、係り元と係り先のトークン（形態素や文節などの単位）をタブ区切り形式ですべて抽出せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2875,
     "status": "ok",
     "timestamp": 1753409988130,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "xBbOWyU65M3E",
    "outputId": "37108955-4295-4345-b3b9-271d31b2760e"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp=spacy.load(\"ja_ginza_electra\")\n",
    "text=\"\"\"\n",
    "メロスは激怒した。\n",
    "必ず、かの邪智暴虐の王を除かなければならぬと決意した。\n",
    "メロスには政治がわからぬ。\n",
    "メロスは、村の牧人である。\n",
    "笛を吹き、羊と遊んで暮して来た。\n",
    "けれども邪悪に対しては、人一倍に敏感であった。\n",
    "\"\"\"\n",
    "\n",
    "doc=nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text}\\t{token.head.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3278,
     "status": "ok",
     "timestamp": 1753409991410,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "5Oc4A8z59JiU",
    "outputId": "33819111-a316-4ef3-9e47-b52615ad3b90"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# GiNZA ELECTRAモデルの読み込み\n",
    "nlp = spacy.load(\"ja_ginza_electra\")\n",
    "\n",
    "# 対象テキスト\n",
    "text = \"\"\"\n",
    "メロスは激怒した。\n",
    "必ず、かの邪智暴虐の王を除かなければならぬと決意した。\n",
    "メロスには政治がわからぬ。\n",
    "メロスは、村の牧人である。\n",
    "笛を吹き、羊と遊んで暮して来た。\n",
    "けれども邪悪に対しては、人一倍に敏感であった。\n",
    "\"\"\"\n",
    "\n",
    "# GiNZAで係り受け解析を実行\n",
    "doc = nlp(text)\n",
    "\n",
    "# 結果をリストで保持\n",
    "rows = []\n",
    "for token in doc:\n",
    "    rows.append({\n",
    "        \"表層形\": token.text,\n",
    "        \"原形\": token.lemma_,\n",
    "        \"品詞\": token.pos_,\n",
    "        \"係り受け関係\": token.dep_,\n",
    "        \"係り先の単語\": token.head.text,\n",
    "        \"係り元の位置\": token.i,\n",
    "        \"係り先の位置\": token.head.i\n",
    "    })\n",
    "\n",
    "# pandasのDataFrameに変換\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Colabで見やすく表示（テーブル形式）\n",
    "display(df.style.set_table_styles([\n",
    "    {'selector': 'thead th', 'props': [('background-color', '#f0f0f0'), ('color', 'black')]},\n",
    "    {'selector': 'tbody td', 'props': [('text-align', 'center')]}\n",
    "]).set_properties(**{'border': '1px solid gray', 'padding': '5px'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpFie1oC8Go8"
   },
   "source": [
    "# 34:主述の関係\n",
    "文章textにおいて、「メロス」が主語であるときの述語を抽出せよ。\n",
    "[出力の読み方(主語がどれか)](https://note.com/npaka/n/n5c3e4ca67956#PrfvI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1846,
     "status": "ok",
     "timestamp": 1753410113635,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "REukdZvo5xF0",
    "outputId": "17be19d0-6873-482b-85d8-25ac37792af2"
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "nlp=spacy.load(\"ja_ginza\")\n",
    "\n",
    "text=\"\"\"\n",
    "メロスは激怒した。\n",
    "必ず、かの邪智暴虐の王を除かなければならぬと決意した。\n",
    "メロスには政治がわからぬ。\n",
    "メロスは、村の牧人である。\n",
    "笛を吹き、羊と遊んで暮して来た。\n",
    "けれども邪悪に対しては、人一倍に敏感であった。\n",
    "\"\"\"\n",
    "\n",
    "doc=nlp(text)\n",
    "\n",
    "predicates=[]\n",
    "\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        if token.text==\"メロス\" and token.dep_==\"nsubj\":\n",
    "            head=token.head\n",
    "            if head.pos_ in (\"VERB\",\"AUX\"):\n",
    "                predicates.append(head.text)\n",
    "            elif head.pos_==\"NOUN\":\n",
    "                cop_found=None\n",
    "                fixed_found=None\n",
    "                for child in head.children:\n",
    "                    if child.dep_ == \"cop\":\n",
    "                        cop_found = child\n",
    "                        for grandchild in child.children:\n",
    "                            if grandchild.dep_ == \"fixed\":\n",
    "                                fixed_found = grandchild\n",
    "                if cop_found and fixed_found:\n",
    "                    predicates.append(f\"{head.text}{cop_found.text}{fixed_found.text}\")  # e.g., 牧人である\n",
    "                elif cop_found:\n",
    "                    predicates.append(f\"{head.text}{cop_found.text}\")  # 牧人で\n",
    "                else:\n",
    "                    predicates.append(head.text)  # 名詞単独\n",
    "\n",
    "print(sorted(set(predicates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR2vpe3VH_dV"
   },
   "source": [
    "# 35:係り受け木\n",
    "「メロスは激怒した。」の係り受け木を可視化せよ。\n",
    "\n",
    "[【初心者向け】自然言語処理ツール「GiNZA」を用いた言語解析（形態素解析からベクトル化まで）](https://qiita.com/cove_ht/items/63ffdd8ff237d4845566#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1753410116959,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "kPogQLey6Nww",
    "outputId": "ad8ceb6a-7390-4c6d-d80c-48b066d38b87"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import display, HTML\n",
    "import spacy\n",
    "\n",
    "nlp=spacy.load(\"ja_ginza\")\n",
    "text=\"メロスは激怒した。\"\n",
    "doc=nlp(text)\n",
    "\n",
    "html=displacy.render(doc,style=\"dep\",options={\"compact\":True})\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4Yuu95FJz4u"
   },
   "source": [
    "# 36~39\n",
    "問題36から39までは、Wikipediaの記事を以下のフォーマットで書き出したファイルjawiki-country.json.gzをコーパスと見なし、統計的な分析を行う。\n",
    "\n",
    "1行に1記事の情報がJSON形式で格納される\n",
    "各行には記事名が”title”キーに、記事本文が”text”キーの辞書オブジェクトに格納され、そのオブジェクトがJSON形式で書き出される\n",
    "ファイル全体はgzipで圧縮される\n",
    "\n",
    "\n",
    "[Colab環境でMeCabを使う3行](https://qiita.com/Ninagawa123/items/c90cccb453e2a6fc4466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4485,
     "status": "ok",
     "timestamp": 1753410129179,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "n71-O7faOcRN",
    "outputId": "ea18c59b-5b07-4b7e-a276-c99c4e5a463c"
   },
   "outputs": [],
   "source": [
    "! pip install mecab-python3 unidic-lite\n",
    "import MeCab\n",
    "print(MeCab.Tagger().parse(\"これはテストです\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgQdqjVLJvJa"
   },
   "source": [
    "# 36:単語の出現頻度\n",
    "まず、第3章の処理内容を参考に、Wikipedia記事からマークアップを除去し、各記事のテキストを抽出せよ。そして、コーパスにおける単語（形態素）の出現頻度を求め、出現頻度の高い20語とその出現頻度を表示せよ。\n",
    "\n",
    "[MeCabの出力形式を整理して、Pandasで扱えるようにした](https://qiita.com/hasoya/items/0561bb1481a648aa8e6e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15607,
     "status": "ok",
     "timestamp": 1753410144788,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "WO2swNDOK0m2",
    "outputId": "1d32f8d1-5efb-4d65-ad8d-3305147210e1"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import MeCab\n",
    "\n",
    "tagger = MeCab.Tagger()\n",
    "file_path = \"/content/drive/MyDrive/jawiki-country.json.gz\"\n",
    "word_counter = Counter()\n",
    "\n",
    "with gzip.open(file_path, mode='rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        article = json.loads(line)\n",
    "        text = article.get(\"text\", \"\")\n",
    "        clean_text = re.sub(r'\\[\\[.*?\\]\\]', '', text)\n",
    "        clean_text = re.sub(r\"''+\", '', clean_text)\n",
    "        node = tagger.parseToNode(clean_text)\n",
    "        while node:\n",
    "            surface = node.surface\n",
    "            features = node.feature.split(',')\n",
    "            pos = features[0]\n",
    "            if not pos.startswith(\"補助記号\") and not pos.startswith(\"助詞\") and not pos.startswith(\"助動詞\"):\n",
    "                word_counter[surface] += 1\n",
    "            node = node.next\n",
    "\n",
    "for word, freq in word_counter.most_common(20):\n",
    "    print(f\"{word}\\t{freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2VIpWf6W4b-"
   },
   "source": [
    "# 37:名詞の出現頻度\n",
    "コーパスにおける名詞の出現頻度を求め、出現頻度の高い20語とその出現頻度を表示せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9909,
     "status": "ok",
     "timestamp": 1753410374874,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "WAe64YwQVjXC",
    "outputId": "693a9284-91ef-4361-a875-deb8fb7e0a46"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from collections import Counter\n",
    "import MeCab\n",
    "\n",
    "tagger = MeCab.Tagger()\n",
    "file_path = \"/content/drive/MyDrive/jawiki-country.json.gz\"\n",
    "noun_counter = Counter()\n",
    "\n",
    "with gzip.open(file_path, mode='rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        article = json.loads(line)\n",
    "        text = article.get(\"text\", \"\")\n",
    "        node = tagger.parseToNode(text)\n",
    "        while node:\n",
    "            features = node.feature.split(',')\n",
    "            if features[0] == \"名詞\":\n",
    "                surface = node.surface\n",
    "                noun_counter[surface] += 1\n",
    "            node = node.next\n",
    "\n",
    "for word, freq in noun_counter.most_common(20):\n",
    "    print(f\"{word}\\t{freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7joDcXVqcBTR"
   },
   "source": [
    "# 38:TF・IDF\n",
    "日本に関する記事における名詞のTF・IDFスコアを求め、TF・IDFスコア上位20語とそのTF, IDF, TF・IDFを表示せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1753411217939,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "yRiw3IgWcGfu",
    "outputId": "e2d6de32-81a1-42f8-9934-3adb2a513eaa"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "import MeCab\n",
    "\n",
    "tagger = MeCab.Tagger()\n",
    "tf_list = []\n",
    "df_counter = Counter()\n",
    "file_path = \"/content/drive/MyDrive/jawiki-country.json.gz\"\n",
    "\n",
    "with gzip.open(file_path, mode='rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        article = json.loads(line)\n",
    "        text = article.get(\"text\", \"\")\n",
    "        title = article.get(\"title\", \"\")\n",
    "        if \"日本\" not in title:\n",
    "            continue\n",
    "        clean_text = re.sub(r'\\[\\[.*?\\]\\]', '', text)\n",
    "        clean_text = re.sub(r\"''+\", '', clean_text)\n",
    "        noun_counter = Counter()\n",
    "        seen_terms = set()\n",
    "        node = tagger.parseToNode(clean_text)\n",
    "        while node:\n",
    "            surface = node.surface\n",
    "            features = node.feature.split(',')\n",
    "            pos = features[0]\n",
    "            if pos.startswith(\"名詞\"):\n",
    "                noun_counter[surface] += 1\n",
    "                seen_terms.add(surface)\n",
    "            node = node.next\n",
    "        tf_list.append(noun_counter)\n",
    "        for term in seen_terms:\n",
    "            df_counter[term] += 1\n",
    "\n",
    "N = len(tf_list)\n",
    "tfidf_scores = defaultdict(float)\n",
    "\n",
    "for tf in tf_list:\n",
    "    total_terms = sum(tf.values())\n",
    "    for term, freq in tf.items():\n",
    "        tf_value = freq / total_terms\n",
    "        df = df_counter[term]\n",
    "        idf = math.log((N + 1) / (df + 1)) + 1\n",
    "        tfidf_scores[term] += tf_value * idf\n",
    "\n",
    "for term, score in sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    tf_sum = sum(tf[term] for tf in tf_list if term in tf)\n",
    "    idf = math.log((N + 1) / (df_counter[term] + 1)) + 1\n",
    "    print(f\"{term}\\tTF: {tf_sum:.4f}\\tIDF: {idf:.4f}\\tTF-IDF: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F9hi_r8fal0"
   },
   "source": [
    "# 39:Zipfの法則（ジップの法則）\n",
    "コーパスにおける単語の出現頻度順位を横軸、その出現頻度を縦軸として、両対数グラフをプロットせよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43255,
     "status": "ok",
     "timestamp": 1753411902814,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "2MdMMlgdfa2L",
    "outputId": "f79a344f-d309-438f-a7d8-1112885d8005"
   },
   "outputs": [],
   "source": [
    "# MeCabと辞書のインストールが必要です（初回のみ）\n",
    "!apt install -y mecab libmecab-dev mecab-ipadic-utf8\n",
    "!pip install mecab-python3 unidic-lite\n",
    "\n",
    "# IPAexフォントがなければこちらで追加\n",
    "!apt install fonts-ipaexfont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1753412311468,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "jZH-YGXYgDrt",
    "outputId": "23954447-75af-4b25-af7f-0651abfe905f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "for font in fm.findSystemFonts(fontpaths=None, fontext='ttf'):\n",
    "    if 'ipa' in font.lower():\n",
    "        print(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "executionInfo": {
     "elapsed": 10755,
     "status": "ok",
     "timestamp": 1753412556322,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "4RteLSb0f02k",
    "outputId": "e37bfcaa-85ee-4c05-8082-11de644224c2"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import MeCab\n",
    "\n",
    "font_path = \"/usr/share/fonts/opentype/ipaexfont-gothic/ipaexg.ttf\"\n",
    "fp = fm.FontProperties(fname=font_path)\n",
    "\n",
    "tagger = MeCab.Tagger()\n",
    "word_counter = Counter()\n",
    "file_path = \"/content/drive/MyDrive/jawiki-country.json.gz\"\n",
    "\n",
    "with gzip.open(file_path, mode='rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        article = json.loads(line)\n",
    "        text = article.get(\"text\", \"\")\n",
    "        clean_text = re.sub(r'\\[\\[.*?\\]\\]', '', text)\n",
    "        clean_text = re.sub(r\"''+\", '', clean_text)\n",
    "\n",
    "        node = tagger.parseToNode(clean_text)\n",
    "        while node:\n",
    "            surface = node.surface\n",
    "            features = node.feature.split(',')\n",
    "            pos = features[0]\n",
    "            if pos.startswith(\"名詞\"):\n",
    "                word_counter[surface] += 1\n",
    "            node = node.next\n",
    "\n",
    "sorted_counts = word_counter.most_common()\n",
    "ranks = list(range(1, len(sorted_counts) + 1))\n",
    "frequencies = [freq for _, freq in sorted_counts]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ranks, frequencies)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"出現頻度順位（対数）\", fontproperties=fp)\n",
    "plt.ylabel(\"出現頻度（対数）\", fontproperties=fp)\n",
    "plt.title(\"Zipfの法則に基づく単語頻度分布（日本語 Wikipedia）\", fontproperties=fp)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPrhoeF_f8KT"
   },
   "source": [
    "# 最後に実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18502,
     "status": "ok",
     "timestamp": 1753413310944,
     "user": {
      "displayName": "Kuramoto Mana",
      "userId": "07313283856042137724"
     },
     "user_tz": -540
    },
    "id": "p1FOO5J9K6NG",
    "outputId": "34680df7-4cf4-4368-accb-42f7400caa61"
   },
   "outputs": [],
   "source": [
    "# 1. Google Driveをマウント\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. クリーンアップツールをインストール\n",
    "!pip install nbstripout -q\n",
    "\n",
    "# 3. ★★★ 自分のノートブックのパスに書き換える ★★★\n",
    "NOTEBOOK_PATH = \"/content/drive/MyDrive/Colab Notebooks/100本ノック第4章.ipynb のコピー (1)\"\n",
    "\n",
    "# 4. nbstripoutを実行して、ノートブックから不要なメタデータを削除\n",
    "!nbstripout \"{NOTEBOOK_PATH}\"\n",
    "\n",
    "print(f\"\\n✅ クリーンアップ完了: {NOTEBOOK_PATH}\")\n",
    "print(\"このファイルをGoogle DriveからダウンロードしてGitHubにアップロードしてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhT2XPKKk5Di"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOOHHk4E1qwP6FOrVZFDb0R",
   "mount_file_id": "14cP5ZNkXDBDoJgdIdMWa19DbHtmbiu0t",
   "provenance": [
    {
     "file_id": "https://github.com/kura-404/NLP100/blob/main/100%E6%9C%AC%E3%83%8E%E3%83%83%E3%82%AF%E7%AC%AC4%E7%AB%A0.ipynb",
     "timestamp": 1753413062691
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
