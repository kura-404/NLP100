

まず1行目、

import MeCab

ここでは、形態素解析エンジン「MeCab」のPython用バインディングをインポートしています。これによりPython上で日本語の文章を単語ごとに分解したり、品詞を調べたりできるようになります。

⸻

次に、解析対象の日本語の文章を複数行にわたって定義しています。

text = """
メロスは激怒した。
...
"""

この部分が、今回形態素解析を行う文章の本文です。

⸻

次にMeCabの解析器（Tagger）を作成します。

tagger = MeCab.Tagger()

この Tagger() オブジェクトを使って、文字列を解析していきます。

⸻


parsed_text = tagger.parse(text)

ここで、文章全体を一括で解析し、形態素ごとの情報を含む文字列として取得しています。

⸻

次のステップでは、抽出したい「動詞の原型」を保存するための空のリストを用意します。

verbs = []


⸻

次の for 文では、解析結果を1行ずつ処理しています。

for line in parsed_text.split('\n'):

MeCabの出力は1語1行になっているので、それを改行で分けて順に処理します。

⸻


if line == 'EOS' or line == '':
    continue

EOSはEnd Of Sentence（文の終わり）のマークで、処理対象から外します。空行も同様にスキップします。

⸻


surface, feature = line.split('\t')
features = feature.split(',')

1行は「単語の形（表層形）」と「品詞情報」に分かれているので、それぞれ \t（タブ）と ,（カンマ）で分解しています。

⸻


if features[0] == '動詞':

この行で「品詞が動詞」であるかどうかを確認しています。動詞だけを対象にしたいのでここで絞り込みます。

⸻


base_form = features[6]

ここがポイントです。featuresの6番目に「原型（基本形）」が入っています。例えば「した」なら「する」、「遊んだ」なら「遊ぶ」などです。

⸻


verbs.append((surface, base_form))

この動詞の「表記」と「原型」をペアにしてリストに追加します。

⸻

最後にリストに追加したすべての動詞ペアを表示します。

for surface, base in verbs:
    print(f"{surface} → {base}")


⸻

これで一通りの処理が終わりです。MeCabを使えば、文章を品詞ごとに分解し、意味のある単語や語形のパターンを簡単に扱えるようになります。

⸻

以上が、このコードの一行ずつの初心者向け解説でした。必要があれば、次はこのデータをCSVに書き出したり、名詞や形容詞を扱う応用も紹介できます。