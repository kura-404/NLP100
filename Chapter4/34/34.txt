	1.	import spacy
→ 最初に、自然言語処理ライブラリ「spaCy（スペイシー）」を使えるようにします。
	2.	nlp = spacy.load("ja_ginza")
→ spaCyに、GiNZAという日本語用の分析モデルを読み込ませます。これで日本語の文を解析できるようになります。
	3.	text = """ ... """
→ 複数行の日本語の文章をまとめて text という変数に入れています。この文章に出てくる「メロス」がどういう動作をしているかを調べます。
	4.	doc = nlp(text)
→ GiNZAを使って文章を解析し、文や単語の情報を含む doc というデータに変換しています。
	5.	predicates = []
→ 結果として取り出す「述語」（メロスが行った動作や状態）を保存するための空のリストを用意しています。
	6.	for sent in doc.sents:
→ 全体の文章を文ごとに処理するためのループです。
	7.	for token in sent:
→ その文に出てくる単語を1つずつ取り出して調べます。
	8.	if token.text == "メロス" and token.dep_ == "nsubj":
→ 「メロス」が主語として使われているかどうかをチェックしています。
	9.	head = token.head
→ 「メロス」がどの単語にかかっているか、つまり「述語」になる語を取得します。
	10.	if head.pos_ in ("VERB", "AUX"):
→ 述語が動詞や助動詞であれば、それをそのまま記録します。
	11.	elif head.pos_ == "NOUN":
→ 述語が名詞（例：「牧人である」などのパターン）の場合は、さらに詳しく調べます。
	12.	cop_found = None / fixed_found = None
→ 「で」や「ある」のような補助語を探すための準備です。
	13.	for child in head.children:
→ 「牧人」などの名詞にくっついている単語を調べます。
	14.	if child.dep_ == "cop":
→ 助動詞っぽい「で」などがあるかどうかを確認します。
	15.	for grandchild in child.children:
→ さらにその「で」に「ある」がくっついているかもチェックします。
	16.	if cop_found and fixed_found:
→ 「名詞 + で + ある」の形になっていたら、全部まとめて述語として記録します。
	17.	elif cop_found:
→ 「名詞 + で」だけだったら、そこまでを述語とします。
	18.	else:
→ それもなければ、名詞だけを述語として記録します。
	19.	print(sorted(set(predicates)))
→ 集めた述語を重複なしで、順番を整えて表示します。